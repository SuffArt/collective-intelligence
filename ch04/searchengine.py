class crawler:
# Initialize the crawler with the name of database 
def __init__(self,dbname):
  pass

def __del__(self): 
  pass

def dbcommit(self):
  pass
  
# Auxilliary function for getting an entry id and adding
 # it if it's not present
def getentryid(self,table,field,value,createnew=True):
  return None
  
# Index an individual page
def addtoindex(self,url,soup):
  print 'Indexing %s' % url

# Extract the text from an HTML page (no tags)
def gettextonly(self,soup):
  return None
  # Separate the words by any non-whitespace character
def separatewords(self,text):
  return None